{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff88f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.distributions import Categorical\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as Data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as ltb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "import scikitplot as skplt\n",
    "from sklearn import tree\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f550669",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "my_Y_train.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m public_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampleSubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m Y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_Y_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_Y_train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m Y_valid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_Y_valid.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_train_X.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Apps\\anacoda\\envs\\gpu1\\lib\\site-packages\\numpy\\lib\\npyio.py:1977\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[0;32m   1975\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1977\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1978\u001b[0m     fid_ctx \u001b[38;5;241m=\u001b[39m contextlib\u001b[38;5;241m.\u001b[39mclosing(fid)\n\u001b[0;32m   1979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Apps\\anacoda\\envs\\gpu1\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Apps\\anacoda\\envs\\gpu1\\lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: my_Y_train.csv not found."
     ]
    }
   ],
   "source": [
    "public_test = pd.read_csv(\"sampleSubmission.csv\")\n",
    "Y_test = np.genfromtxt(\"my_Y_test.csv\", delimiter=',')\n",
    "Y_train = np.genfromtxt(\"my_Y_train.csv\", delimiter=',')\n",
    "Y_valid = np.genfromtxt(\"my_Y_valid.csv\", delimiter=',')\n",
    "\n",
    "X = pd.read_csv(\"my_train_X.csv\", header=None)\n",
    "y = pd.read_csv(\"my_train_y.csv\", header=None)\n",
    "test = pd.read_csv(\"my_test.csv\", header=None)\n",
    "\n",
    "X_copy = X.copy()\n",
    "y_copy = y.copy()\n",
    "test_copy = test.copy()\n",
    "\n",
    "X_arr = X_copy.to_numpy()\n",
    "y_arr = y_copy.to_numpy()\n",
    "test_arr = test_copy.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train.astype(np.float32))\n",
    "y_train_t = torch.from_numpy(y_train.astype(np.float32))\n",
    "X_test_t = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_test_t = torch.from_numpy(y_test.astype(np.float32))\n",
    "test_X = torch.tensor(test_arr,dtype=torch.float32)\n",
    "\n",
    "X_test_t = X_test_t.to(device)\n",
    "y_test_t = y_test_t.to(device)\n",
    "test_X = test_X.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = LinearRegression(fit_intercept = False).fit(Y_train, y_train)\n",
    "weight = regs.coef_\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74734020",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_pred = regs.predict(Y_train)\n",
    "valid_Y_pred = regs.predict(Y_valid)\n",
    "mean_squared_error(train_Y_pred, y_train) ** 0.5, mean_squared_error(valid_Y_pred, y_test) ** 0.5, mean_squared_error(train_Y_pred, y_train), mean_squared_error(valid_Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = regs.predict(Y_test)\n",
    "public_test[\"TRAVEL_TIME\"] = p\n",
    "public_test.to_csv(\"p.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08157c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(MLP, self).__init__() #Refers to the fact that this is a subclass of nn.Module and is inheriting all methods\n",
    "        self.model = torch.nn.Sequential( #an ordered container of modules\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "           ## nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(128, 64),\n",
    "           ## nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64,32),\n",
    "           ## nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(32, 1)\n",
    "        )   \n",
    "    def forward(self, x): #You never have to call model.forward(x)\n",
    "        \"\"\"\n",
    "        the forward function is where computatioin gets done\n",
    "        \"\"\"\n",
    "        out = self.model(x)    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 128\n",
    "model_mlp = MLP(input_size, hidden_size)\n",
    "model_mlp.to(device)\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model_mlp.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27413dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():  \n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = (criterion(outputs, labels).item())*inputs.size(0)\n",
    "            running_loss += loss\n",
    "    return np.sqrt(running_loss / len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_t = torch.from_numpy(Y_train.astype(np.float32))\n",
    "y_train_t = torch.from_numpy(y_train.astype(np.float32))\n",
    "Y_valid_t = torch.from_numpy(Y_valid.astype(np.float32))\n",
    "y_test_t = torch.from_numpy(y_test.astype(np.float32))\n",
    "test_y = torch.tensor(Y_test,dtype=torch.float32)\n",
    "\n",
    "train_data = Data.TensorDataset(Y_train_t, y_train_t)\n",
    "test_data = Data.TensorDataset(Y_valid_t, y_test_t)\n",
    "train_loader = Data.DataLoader(dataset = train_data, batch_size = 30, \n",
    "                               shuffle = True, num_workers = 2)\n",
    "test_loader = Data.DataLoader(dataset = test_data, batch_size = 30, \n",
    "                               shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc26841",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "mses = []\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model_mlp.train()\n",
    "    for i,(b_x, b_y) in tqdm(enumerate(train_loader)):\n",
    "        inputs = b_x.to(device)\n",
    "        labels = b_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model_mlp(inputs)\n",
    "        loss = criterion(prediction,labels)\n",
    "        running_loss +=loss.item()*inputs.size(0) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    rmse = np.sqrt(running_loss/len(X_train))\n",
    "    validation_loss = validate(model_mlp, test_loader, criterion)\n",
    "    rmses.append((rmse, validation_loss))\n",
    "    mses.append((rmse ** 2, validation_loss ** 2))\n",
    "    print(  'Epoch: {}/{}\\t'.format(epoch+1, num_epochs),\n",
    "            'Training Loss: {:.3f}\\t'.format(rmse),\n",
    "            'Validation Loss: {:.3f}\\t'.format(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.to(device)\n",
    "model_mlp.eval()\n",
    "prediction = model_mlp(test_y)\n",
    "results = torch.squeeze(prediction, 1)\n",
    "torch.save(model_mlp, \"combined_mlp_10epoch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c10ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for i in range(len(results)):\n",
    "    result_list.append(results[i].item())\n",
    "public_test[\"TRAVEL_TIME\"] = result_list\n",
    "public_test.to_csv(\"my_pred_mlps_combined.csv\", index=None)\n",
    "public_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09274a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses, mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff8bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf926a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b12481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

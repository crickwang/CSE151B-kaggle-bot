{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff88f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.distributions import Categorical\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as Data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as ltb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "import scikitplot as skplt\n",
    "from sklearn import tree\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f550669",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_test = pd.read_csv(\"sampleSubmission.csv\")\n",
    "Y_test = np.genfromtxt(\"my_Y_test.csv\", delimiter=',')\n",
    "Y_train = np.genfromtxt(\"my_Y_train.csv\", delimiter=',')\n",
    "Y_valid = np.genfromtxt(\"my_Y_valid.csv\", delimiter=',')\n",
    "\n",
    "X = pd.read_csv(\"my_train_X.csv\", header=None)\n",
    "y = pd.read_csv(\"my_train_y.csv\", header=None)\n",
    "test = pd.read_csv(\"my_test.csv\", header=None)\n",
    "\n",
    "X_copy = X.copy()\n",
    "y_copy = y.copy()\n",
    "test_copy = test.copy()\n",
    "\n",
    "X_arr = X_copy.to_numpy()\n",
    "y_arr = y_copy.to_numpy()\n",
    "test_arr = test_copy.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train.astype(np.float32))\n",
    "y_train_t = torch.from_numpy(y_train.astype(np.float32))\n",
    "X_test_t = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_test_t = torch.from_numpy(y_test.astype(np.float32))\n",
    "test_X = torch.tensor(test_arr,dtype=torch.float32)\n",
    "\n",
    "X_test_t = X_test_t.to(device)\n",
    "y_test_t = y_test_t.to(device)\n",
    "test_X = test_X.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871d290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.23506103e+00,  7.56998310e+00,  2.44068501e-03,\n",
       "        -7.64377281e+00, -1.68795368e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regs = LinearRegression(fit_intercept = False).fit(Y_train, y_train)\n",
    "weight = regs.coef_\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74734020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373.2962528844896, 374.1061004772205, 139350.09241760083, 139955.3744142722)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_pred = regs.predict(Y_train)\n",
    "valid_Y_pred = regs.predict(Y_valid)\n",
    "mean_squared_error(train_Y_pred, y_train) ** 0.5, mean_squared_error(valid_Y_pred, y_test) ** 0.5, mean_squared_error(train_Y_pred, y_train), mean_squared_error(valid_Y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccc3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = regs.predict(Y_test)\n",
    "public_test[\"TRAVEL_TIME\"] = p\n",
    "public_test.to_csv(\"p.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08157c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(MLP, self).__init__() #Refers to the fact that this is a subclass of nn.Module and is inheriting all methods\n",
    "        self.model = torch.nn.Sequential( #an ordered container of modules\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "           ## nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(128, 64),\n",
    "           ## nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64,32),\n",
    "           ## nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(32, 1)\n",
    "        )   \n",
    "    def forward(self, x): #You never have to call model.forward(x)\n",
    "        \"\"\"\n",
    "        the forward function is where computatioin gets done\n",
    "        \"\"\"\n",
    "        out = self.model(x)    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ce8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 128\n",
    "model_mlp = MLP(input_size, hidden_size)\n",
    "model_mlp.to(device)\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model_mlp.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27413dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():  \n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = (criterion(outputs, labels).item())*inputs.size(0)\n",
    "            running_loss += loss\n",
    "    return np.sqrt(running_loss / len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f3d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_t = torch.from_numpy(Y_train.astype(np.float32))\n",
    "y_train_t = torch.from_numpy(y_train.astype(np.float32))\n",
    "Y_valid_t = torch.from_numpy(Y_valid.astype(np.float32))\n",
    "y_test_t = torch.from_numpy(y_test.astype(np.float32))\n",
    "test_y = torch.tensor(Y_test,dtype=torch.float32)\n",
    "\n",
    "train_data = Data.TensorDataset(Y_train_t, y_train_t)\n",
    "test_data = Data.TensorDataset(Y_valid_t, y_test_t)\n",
    "train_loader = Data.DataLoader(dataset = train_data, batch_size = 30, \n",
    "                               shuffle = True, num_workers = 2)\n",
    "test_loader = Data.DataLoader(dataset = test_data, batch_size = 30, \n",
    "                               shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc26841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40932it [01:59, 342.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\t Training Loss: 394.131\t Validation Loss: 375.864\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40932it [01:53, 359.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10\t Training Loss: 392.848\t Validation Loss: 375.287\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40932it [01:51, 368.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10\t Training Loss: 392.524\t Validation Loss: 376.967\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13098it [00:38, 342.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(prediction,labels)\n\u001b[0;32m     13\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39minputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m---> 15\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     17\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(running_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train))\n",
      "File \u001b[1;32m~\\Apps\\anacoda\\envs\\gpu1\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Apps\\anacoda\\envs\\gpu1\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "mses = []\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model_mlp.train()\n",
    "    for i,(b_x, b_y) in tqdm(enumerate(train_loader)):\n",
    "        inputs = b_x.to(device)\n",
    "        labels = b_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model_mlp(inputs)\n",
    "        loss = criterion(prediction,labels)\n",
    "        running_loss +=loss.item()*inputs.size(0) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    rmse = np.sqrt(running_loss/len(X_train))\n",
    "    validation_loss = validate(model_mlp, test_loader, criterion)\n",
    "    rmses.append((rmse, validation_loss))\n",
    "    mses.append((rmse ** 2, validation_loss ** 2))\n",
    "    print(  'Epoch: {}/{}\\t'.format(epoch+1, num_epochs),\n",
    "            'Training Loss: {:.3f}\\t'.format(rmse),\n",
    "            'Validation Loss: {:.3f}\\t'.format(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.to(device)\n",
    "prediction = model_mlp(test_y)\n",
    "results = torch.squeeze(prediction, 1)\n",
    "torch.save(model_mlp, \"combined_mlp_10epoch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c10ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for i in range(len(results)):\n",
    "    result_list.append(results[i].item())\n",
    "public_test[\"TRAVEL_TIME\"] = result_list\n",
    "public_test.to_csv(\"my_pred_mlps_combined.csv\", index=None)\n",
    "public_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09274a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses, mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff8bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf926a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b12481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
